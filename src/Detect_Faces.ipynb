{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detect-Faces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufc87MkP7KLw",
        "colab_type": "text"
      },
      "source": [
        "### Dedicated for extracting faces from any given input using the finetuned Detectron2 model\n",
        "(Either a video, a multi-faced image or the custom dataset used to evaluate the system)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1gs1_eoODyn",
        "colab_type": "text"
      },
      "source": [
        "#### Installing Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyNDmYBdN5kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q cython pyyaml==5.1\n",
        "!pip install -q -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -q -e detectron2_repo\n",
        "!gdown --id 18Ev2bpdKsBaDufhVKf0cT6RmM3FjW3nL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9dXp1I3OrPe",
        "colab_type": "text"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFU00MVFOnrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2 import model_zoo\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfMUxrPdHuAq",
        "colab_type": "text"
      },
      "source": [
        "#### Load the finetuned detectron2\n",
        "Specify hyperparameters to run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5eix5E5OZG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.DATASETS.TRAIN = (\"faces_train\",)\n",
        "cfg.DATASETS.TEST = (\"faces_val\", )\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
        "cfg.merge_from_file(\n",
        "  model_zoo.get_config_file(\n",
        "    \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
        "  )\n",
        ")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
        "statement_metadata = MetadataCatalog.get(\"faces_train\")\n",
        "cfg.MODEL.WEIGHTS = \"face_detector.pth\"\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sBhyoAzH06F",
        "colab_type": "text"
      },
      "source": [
        "#### Detect faces in a image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijgfuz_RPQEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_img(im, mode='single'):\n",
        "  ''' Finds the bounding boxes of faces in an image '''\n",
        "  \n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(\n",
        "    im[:, :, ::-1],\n",
        "    metadata=statement_metadata, \n",
        "    scale=1., \n",
        "    instance_mode=ColorMode.IMAGE\n",
        "  )\n",
        "  instances = outputs[\"instances\"].to(\"cpu\")\n",
        "  instances.remove('pred_masks')\n",
        "  # If multiple faces, save in numpy array otherwise in a csv\n",
        "  if mode == 'multiple':\n",
        "    bounding_box = np.array(instances.get('pred_boxes').tensor).astype('int')\n",
        "    return bounding_box\n",
        "  else:\n",
        "    if np.array(instances.get('pred_boxes').tensor).shape[0] == 0:\n",
        "      plt.imshow(im)\n",
        "      return -1, -1, -1, -1, None\n",
        "    else:\n",
        "      bounding_box = np.array(instances.get('pred_boxes').tensor)[0].astype('int')\n",
        "      x1, y1, x2, y2 = bounding_box[0], bounding_box[1], bounding_box[2], bounding_box[3]\n",
        "  \n",
        "  # Prepare an image that contains the face bounds\n",
        "  v = v.draw_instance_predictions(instances)\n",
        "  result = v.get_image()[:, :, ::-1]\n",
        "  return x1, y1, x2, y2, result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMk1NwaFH8eu",
        "colab_type": "text"
      },
      "source": [
        "#### Detect faces in a multi-faced image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Z23T90JO7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_multiple_boxes(folder_path):\n",
        "  ''' If image known to have multiple faces, save them in a Numpy array '''\n",
        "\n",
        "  images = []\n",
        "  boxes = []\n",
        "  for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if os.path.isdir(file_path):\n",
        "      continue\n",
        "    \n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    box = detect_img(img, mode='multiple')\n",
        "    images.append(file_path)\n",
        "    boxes.append(box)\n",
        "    \n",
        "  np.save(folder_path+'/arrays/file_names.npy', np.array(images))\n",
        "  np.save(folder_path+'/arrays/boxes.npy', np.array(boxes))\n",
        "\n",
        "all_path = '/content/drive/My Drive/ML/Face_dataset/all_faces'\n",
        "get_multiple_boxes(all_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uVcwm37Itp_",
        "colab_type": "text"
      },
      "source": [
        "#### Save detected faces in a Dataframe for recognition purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya6zM6WhUEV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_boxes(dataset_path):\n",
        "  ''' If the images known to have single faces, \n",
        "  save them in a csv file for training the SVM \n",
        "  '''\n",
        "\n",
        "  images = []\n",
        "  dataset = []\n",
        "  # Enumerate all images for all identity classes\n",
        "  for folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    for filename in os.listdir(folder_path):\n",
        "      file_path = os.path.join(folder_path, filename)\n",
        "      img = cv2.imread(file_path)\n",
        "      x1, y1, x2, y2, result = detect_img(img)\n",
        "      # Save the bounding box and the face label\n",
        "      data = {\n",
        "          'file_name': file_path,\n",
        "          'x_min': x1, 'x_max': x2,\n",
        "          'y_min': y1, 'y_max': y2,\n",
        "          'label': folder\n",
        "      }\n",
        "      dataset.append(data)\n",
        "  return dataset\n",
        "\n",
        "# Save the training and testing data in CSV files\n",
        "train_path = '/content/drive/My Drive/ML/Face_dataset/Train/'\n",
        "train_dataset = get_boxes(train_path)\n",
        "df_train = pd.DataFrame(train_dataset)\n",
        "\n",
        "test_path = '/content/drive/My Drive/ML/Face_dataset/Test/'\n",
        "test_dataset = get_boxes(test_path)\n",
        "df_test = pd.DataFrame(test_dataset)\n",
        "\n",
        "df_train.to_csv('/content/drive/My Drive/ML/Face_dataset/train_boxes.csv')\n",
        "df_test.to_csv('/content/drive/My Drive/ML/Face_dataset/test_boxes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhd1iIoAJCt9",
        "colab_type": "text"
      },
      "source": [
        "#### Test Face detection on a personal video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tEPJrGNaAMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_frames(path):\n",
        "  ''' Detect faces in an input video and save them in a CSV file '''\n",
        "\n",
        "  vidcap = cv2.VideoCapture(path)\n",
        "  # Video parameters\n",
        "  width  = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
        "  height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "  timer = []\n",
        "  video_faces = []\n",
        "  # Output video\n",
        "  fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "  video = cv2.VideoWriter('drive/My Drive/ML/detected_faces.avi', fourcc, fps, (height, width))\n",
        "  # Read frames\n",
        "  while True:\n",
        "    ret, image = vidcap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    t0 = time.time()\n",
        "    x1, y1, x2, y2, result = detect_img(image)\n",
        "    timer.append(time.time() - t0)\n",
        "    data = {\n",
        "          'x_min': x1, 'x_max': x2,\n",
        "          'y_min': y1, 'y_max': y2,\n",
        "    }\n",
        "    video_faces.append(data)\n",
        "    # if frame contains a face, save the face otherwise save the original frame\n",
        "    if result is None:\n",
        "      video.write(image)\n",
        "    else:\n",
        "      video.write(result)\n",
        "  # Save the detected faces in a CSV file\n",
        "  df_video = pd.DataFrame(video_faces)\n",
        "  df_video.to_csv('/content/drive/My Drive/ML/Face_dataset/video_boxes.csv')\n",
        "  cv2.destroyAllWindows()\n",
        "  video.release()\n",
        "  print('Average detection time for 1 frame', np.average(np.array(timer)))\n",
        "\n",
        "video_path = 'drive/My Drive/ML/IMG_5947.MOV'\n",
        "detect_frames(video_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}