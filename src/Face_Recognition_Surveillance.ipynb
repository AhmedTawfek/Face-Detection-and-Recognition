{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition_Surveillance.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX9TSxhkttAK",
        "colab_type": "text"
      },
      "source": [
        "### Test Facenet on Surveillance data\n",
        "Loads 20 identites from the QMUL-SurvFace dataset and recognizes them using Facenet and SVMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0BZHBd6-rLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHt-g8YWH4M6",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1_pPFiqBqQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(img):\n",
        "  ''' Normalizes and image '''\n",
        "  img = img.astype('float32')\n",
        "  mean, std = img.mean(), img.std()\n",
        "  img = (img - mean) / std\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-VGhM9qwiP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85789242-e355-4527-b722-91abbfea5e5d"
      },
      "source": [
        "dir_name = 'drive/My Drive/ML/surv_dataset'\n",
        "def read_dataset(dir_name):\n",
        "  ''' Reads 20 classes, preprocess them\n",
        "   and saves them in Numpy arrays (The operation is time costly)'''\n",
        "\n",
        "  class_names = os.listdir(dir_name)\n",
        "  X = []\n",
        "  y = []\n",
        "  label = 0\n",
        "  count = 0\n",
        "  for c in class_names:\n",
        "    class_path = os.path.join(dir_name, c)\n",
        "    if not os.path.isfile(class_path):\n",
        "      file_names = os.listdir(class_path)\n",
        "      if len(file_names) > 0:\n",
        "        for file_name in file_names:\n",
        "          file_path = os.path.join(class_path, file_name)\n",
        "          img = cv2.imread(file_path)\n",
        "          # Preprocessing\n",
        "          img = cv2.resize(img, (160, 160))\n",
        "          img = normalize(img)\n",
        "          X.append(img)\n",
        "          y.append(label)\n",
        "        label += 1\n",
        "    # only 20 identities are needed\n",
        "    if label == 20:\n",
        "      break\n",
        "  # Save the preprocessed faces\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "  np.save('drive/My Drive/ML/X_surv.npy', X)\n",
        "  np.save('drive/My Drive/ML/y_surv.npy', y)\n",
        "\n",
        "read_dataset(dir_name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 62/176 [00:43<01:30,  1.25it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTC3ZCnxH1Pi",
        "colab_type": "text"
      },
      "source": [
        "#### Load Facenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSml5E0u69Fb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e9fd8c5d-a13c-4b76-a497-2a73d0b6442c"
      },
      "source": [
        "model_path = '/drive/My Drive/ML/facenet_keras.h5'\n",
        "model = load_model(model_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKRH1HyOH9wN",
        "colab_type": "text"
      },
      "source": [
        "#### Embed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3GHMttv-pNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "416eb9f0-3c89-4e2a-fab3-b517bd380913"
      },
      "source": [
        "X = np.load('drive/My Drive/ML/X_surv.npy')\n",
        "X = model.predict(X)\n",
        "y = np.load('drive/My Drive/ML/y_surv.npy')\n",
        "X.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4934, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkRjvw4DIBrD",
        "colab_type": "text"
      },
      "source": [
        "#### Split to train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN5HQZHs9qfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0c3a973-0819-4f65-d25c-1f0ae1aff36a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3947, 128), (987, 128))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czl2TaflID_o",
        "colab_type": "text"
      },
      "source": [
        "#### Conduct a Grid search with cross validation on the SVM hyperparameters and report the final metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-0eDiWC5YpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_svm(X_train, y_train, X_test, y_test):\n",
        "  ''' Grid search on the SVM hyperparameters '''\n",
        "  \n",
        "  parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000]}\n",
        "  print(\"# Tuning hyper-parameters \")\n",
        "  clf = GridSearchCV(\n",
        "      SVC(), parameters\n",
        "  )\n",
        "  clf.fit(X_train, y_train)\n",
        "  print(\"Best parameters set found on development set:\")\n",
        "  print(clf.best_params_)\n",
        "  print(\"Grid scores on development set:\")\n",
        "  means = clf.cv_results_['mean_test_score']\n",
        "  stds = clf.cv_results_['std_test_score']\n",
        "  for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "      print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "            % (mean, std * 2, params))\n",
        "  print(\"Detailed classification report:\")\n",
        "  print(\"The model is trained on the full development set.\")\n",
        "  print(\"The scores are computed on the full evaluation set.\")\n",
        "  y_true, y_pred = y_test, clf.predict(X_test)\n",
        "  print(classification_report(y_true, y_pred))\n",
        "\n",
        "svc = fit_svm(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}