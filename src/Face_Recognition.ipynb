{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSHZqSA9B33D",
        "colab_type": "text"
      },
      "source": [
        "### Recognizes faces using Facenet\n",
        "It was used to train the SVM to recognize the custom dataset and apply it on the image that contains multiple faces and on the input video\n",
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttNKeNvPME15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.patches as patches\n",
        "import pickle\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGwl3SuGXWUZ",
        "colab_type": "text"
      },
      "source": [
        "#### Load Face Recognition model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVqJlBi07zHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/drive/My Drive/ML/facenet_keras.h5'\n",
        "model = load_model(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ldHaDoXZiv",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess dataset (crop face, resize)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfU0rR2KLwYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = '/content/drive/My Drive/ML/Face_dataset/'\n",
        "def preprocess_data(df):\n",
        "  ''' Retrieves the faces that were detected and crops and resize them '''\n",
        "  X = []\n",
        "  y = []\n",
        "  for index, row in df.iterrows():\n",
        "    img = cv2.imread(row['file_name'])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    x1, y1, x2, y2 = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
        "    label = row['label']\n",
        "    face = img[y1:y2, x1:x2]\n",
        "    face = cv2.resize(face, (160, 160))\n",
        "    X.append(face)\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "df_train = pd.read_csv(dataset_path+'train_boxes.csv')\n",
        "df_test = pd.read_csv(dataset_path+'test_boxes.csv')\n",
        "X_train, y_train = preprocess_data(df_train)\n",
        "X_test, y_test = preprocess_data(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5R7PG2jXgp6",
        "colab_type": "text"
      },
      "source": [
        "#### Normalize Dataset and embed samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVOMGvZrCvK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding(model, face_pixels):\n",
        "  ''' Normalize the faces and embed them using facenet to 128 feature vector '''\n",
        "\t# scale pixel values\n",
        "\tface_pixels = face_pixels.astype('float32')\n",
        "\t# standardize pixel values across channels (global)\n",
        "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
        "\tface_pixels = (face_pixels - mean) / std\n",
        "\t# transform face into one sample\n",
        "\tsamples = np.expand_dims(face_pixels, axis=0)\n",
        "\t# make prediction to get embedding\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat[0]\n",
        "\n",
        "def embed_dataset(X_train, y_train, X_test, y_test):\n",
        "  ''' Extracts the embeddings and normalize them for all the custom dataset \n",
        "  It also labels the samples with the identites of people in them\n",
        "  '''\n",
        "  train_embeddings = []\n",
        "  test_embeddings = []\n",
        "  # normalize input vectors\n",
        "  in_encoder = Normalizer(norm='l2')\n",
        "  # Training faces\n",
        "  for face_pixels in X_train:\n",
        "    embedding = get_embedding(model, face_pixels)\n",
        "    train_embeddings.append(embedding)\n",
        "  train_embeddings = in_encoder.transform(np.array(train_embeddings))\n",
        "  # Testing faces\n",
        "  for face_pixels in X_test:\n",
        "    embedding = get_embedding(model, face_pixels)\n",
        "    test_embeddings.append(embedding)\n",
        "  test_embeddings = in_encoder.transform(np.array(test_embeddings))\n",
        "  \n",
        "  # Label\n",
        "  out_encoder = LabelEncoder()\n",
        "  out_encoder.fit(y_train)\n",
        "  one_hot_y_train = out_encoder.transform(y_train)\n",
        "  one_hot_y_test = out_encoder.transform(y_test)\n",
        "  return train_embeddings, one_hot_y_train, test_embeddings, one_hot_y_test, out_encoder\n",
        "\n",
        "X_train, y_train, X_test, y_test, out_encoder = embed_dataset(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJAhzetIXy5o",
        "colab_type": "text"
      },
      "source": [
        "#### Fit SVM to the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Qdi5IEVs6M",
        "colab_type": "code",
        "outputId": "e88aaff6-32e1-421b-b305-4d0fff1074c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def fit_svm(X_train, y_train, X_test, y_test):\n",
        "  ''' Trains an SVM on the embeddings and reports accuracy '''\n",
        "  model = SVC(kernel='linear', probability=True)\n",
        "  model.fit(X_train, y_train)\n",
        "  yhat_train = model.predict(X_train)\n",
        "  yhat_test = model.predict(X_test)\n",
        "  # score\n",
        "  score_train = accuracy_score(y_train, yhat_train)\n",
        "  score_test = accuracy_score(y_test, yhat_test)\n",
        "  print(yhat_test)\n",
        "  print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n",
        "  return model\n",
        "svc = fit_svm(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 2 0 2 2 2 1 1 1 1 1 3 3 3 3 3]\n",
            "Accuracy: train=100.000, test=95.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xn2Pn-Dc4c3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pipeline(face, svc):\n",
        "  ''' Recognizes a face by calling all the previous functions '''\n",
        "  face = cv2.resize(face, (160, 160))\n",
        "  embedding = get_embedding(model, face).reshape((1,-1))\n",
        "  in_encoder = Normalizer(norm='l2')\n",
        "  embedding = in_encoder.transform(embedding)\n",
        "  y_prob = svc.predict_proba(embedding)\n",
        "  y = svc.predict(embedding)\n",
        "  return y, np.max(y_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDLDiv3Pb4xe",
        "colab_type": "text"
      },
      "source": [
        "### Custom Test\n",
        "Using a personal photo that contains 3 faces. Can be found in the outputs folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjVg4Vz8b4Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = '/content/drive/My Drive/ML/Face_dataset/all_faces/'\n",
        "file_names = np.load(folder_path+'arrays/file_names.npy')\n",
        "# Load the faces boundaries\n",
        "boxes = np.load(folder_path+'arrays/boxes.npy', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvj2zHuPDfiT",
        "colab_type": "text"
      },
      "source": [
        "#### input the face, apply the pipeline and create a plot that have the face bounds labeled with the person's name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf0T75KIUxv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 3\n",
        "img = cv2.imread(file_names[idx])\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "box = boxes[idx]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "fig = plt.figure(figsize=(40, 40))\n",
        "ax.imshow(img)\n",
        "for b in box:\n",
        "  # Face bounds\n",
        "  x1, y1, x2, y2 = b[0], b[1], b[2], b[3]\n",
        "  face = img[y1:y2, x1:x2]\n",
        "  # predict the face\n",
        "  y, prob = pipeline(face, svc)\n",
        "  title = out_encoder.inverse_transform(y)[0] + '\\n{:.2f}'.format(prob)\n",
        "  # Create rectangle around the face and plot it\n",
        "  rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, \n",
        "                           edgecolor='r', facecolor='none', label=title)\n",
        "  ax.add_patch(rect)\n",
        "  ax.text(x1, y1, title, fontsize=8, color='r', \n",
        "          bbox=dict(facecolor='black'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaw8UxiRcaGO",
        "colab_type": "text"
      },
      "source": [
        "### Video testing\n",
        "Read the frames along with the face bounds, recognize the face and draw the face rectangles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONGE3XE5ViHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_frame(img, row):\n",
        "  ''' Returns the patch that contains the face '''\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  x1, y1, x2, y2 = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
        "  face = img[y1:y2, x1:x2]\n",
        "  return face\n",
        "\n",
        "def recognize_frames(path, df_path):\n",
        "  ''' Read all frames alongside the face bounds in each frame '''\n",
        "\n",
        "  vidcap = cv2.VideoCapture(path)\n",
        "  width  = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))  # float\n",
        "  height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "  timer = []\n",
        "  video_faces = []\n",
        "  # CSV file that contains the face bounds in each frame\n",
        "  df = pd.read_csv(df_path)\n",
        "  print('Number of frames', df.values.shape[0])\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    # Face bounds (if any)\n",
        "    ret, image = vidcap.read()\n",
        "    x1, y1, x2, y2 = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
        "    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    fig, ax = plt.subplots()\n",
        "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img_rgb)\n",
        "    t0 = time.time()\n",
        "    face = read_frame(image, row)\n",
        "\n",
        "    # Recognize face (if any)\n",
        "    if face.shape[0] > 0:\n",
        "      y, prob = pipeline(face, svc)\n",
        "      timer.append(time.time() - t0)\n",
        "      title = out_encoder.inverse_transform(y)[0] + '\\n{:.2f}'.format(prob)\n",
        "      # Draw the face bounds\n",
        "      rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, \n",
        "                          edgecolor='r', facecolor='none', label=title)\n",
        "      ax.add_patch(rect)\n",
        "      ax.text(x1, y1, title, fontsize=8, color='r', \n",
        "              bbox=dict(facecolor='black'))\n",
        "      \n",
        "    # Save the frame with the labeled bounding box\n",
        "    plt.savefig(f'/content/drive/My Drive/ML/Face_dataset/video_frames/{index}.png')\n",
        "  return timer\n",
        "\n",
        "path = 'drive/My Drive/ML/IMG_5947.MOV'\n",
        "df_path = '/content/drive/My Drive/ML/Face_dataset/video_boxes.csv'\n",
        "timer = recognize_frames(path, df_path)\n",
        "print('Recognition time on average for frame', np.average(np.array(timer)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47JuuUsJFBLZ",
        "colab_type": "text"
      },
      "source": [
        "Finally, append all the save frames to create the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW4hqQICiYDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vidcap = cv2.VideoCapture('drive/My Drive/ML/IMG_5947.MOV')\n",
        "width  = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))  # float\n",
        "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "video = cv2.VideoWriter('drive/My Drive/ML/recognized_faces.avi', fourcc, 30, (432, 288))\n",
        "for i in range(398):\n",
        "  img = cv2.imread(f'drive/My Drive/ML/Face_dataset/video_frames/{i}.png')\n",
        "  video.write(img)\n",
        "video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}